{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:87% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:87% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_con-multi/sequencing_summary.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5d99be20e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum_con_fl\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_con-multi/sequencing_summary.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_events'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'template_duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequence_length_template'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_qscore_template'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msum_200_fl\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod-multi/sequencing_summary.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_events'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'template_duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequence_length_template'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_qscore_template'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msum_50_fl\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_lo-multi/sequencing_summary.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_events'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'template_duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequence_length_template'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_qscore_template'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msum_20_fl\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_20-multi/sequencing_summary.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_events'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'template_duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequence_length_template'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_qscore_template'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msum_5_fl\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_5-multi/sequencing_summary.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'read_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_events'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'template_duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequence_length_template'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_qscore_template'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gstore/apps/Anaconda3/5.0.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gstore/apps/Anaconda3/5.0.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gstore/apps/Anaconda3/5.0.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gstore/apps/Anaconda3/5.0.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    993\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[1;32m    994\u001b[0m                                      engine=engine))\n\u001b[0;32m--> 995\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gstore/apps/Anaconda3/5.0.1/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   1983\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[1;32m   1984\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[1;32m   1986\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gstore/apps/Anaconda3/5.0.1/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_con-multi/sequencing_summary.txt'"
     ]
    }
   ],
   "source": [
    "## pri-miR-17~92 [0mM, 5mM, 20mM, 50mM, 75mM, 100mM, 150mM, 200mM] final AcIm concentrations\n",
    "## import sequencing summary files\n",
    "sum_con_fl  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_con-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_200_fl  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_50_fl   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_lo-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_20_fl   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_20-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_5_fl    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_5-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_100_fl  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_100-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_75_fl   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_75-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "sum_150_fl  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/guppy_3.1.5/1792_fl_mod_150-multi/sequencing_summary.txt', sep='\\t', engine='python', usecols=['read_id', 'num_events', 'template_duration', 'sequence_length_template', 'mean_qscore_template'])\n",
    "\n",
    "## import tombo coverage files\n",
    "cov_con    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_con_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_5      = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_5_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_20     = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_20_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_50     = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_50_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_200    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_200_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_100    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_100_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_75    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_75_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "cov_150    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_150_fl.coverage.plus.bedgraph', sep='\\t', skiprows = 1, header = None, usecols=[0,2,3], names=['ref', 'pos', 'cov'], engine='python')\n",
    "\n",
    "## import tombo signal files\n",
    "sig_con    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_5_fl.signal.control.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_5      = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_5_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_20     = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_20_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_50     = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_50_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_200    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_200_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_100    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_100_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_75    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_75_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "sig_150    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_150_fl.signal.sample.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'sig'],  engine='python')\n",
    "\n",
    "## import tombo dwell files\n",
    "dwell_con  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_con_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_5    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_5_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_20   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_20_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_50   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_50_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_200  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_200_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_100  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_100_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_75  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_75_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "dwell_150  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_150_fl.dwell.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'dwell'],  engine='python')\n",
    "\n",
    "## import tombo KS current statistic files\n",
    "stat_5    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_5_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "stat_20   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_20_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "stat_50   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_50_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "stat_200  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_200_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "stat_100  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_100_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "stat_75  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_75_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "stat_150  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_150_fl.statistic.plus.wig', delim_whitespace=True, skiprows = 2, names=['pos', 'stat'],  engine='python')\n",
    "\n",
    "## import tombo KS dwell statistic files\n",
    "stat_dw_5    = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_5_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "stat_dw_20   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_20_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "stat_dw_50   = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_50_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "stat_dw_200  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_200_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "stat_dw_100  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_100_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "stat_dw_75  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_75_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "stat_dw_150  = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/mir_1792/analysis_flongle_conc-series/1792_mod_150_fl.statistic_dwell.plus.wig', delim_whitespace=True, skiprows = 1, names=['pos', 'stat'],  engine='python')\n",
    "\n",
    "## import SHAPE-MaP profile for pri-miR-17~92\n",
    "shape_1ai = pd.read_csv('/gpfs/commons/projects/ont_nanoprobe/gridion_1792_1/analysis/1792_1ai_miR17-92_DNA.shape', sep='\\t', skiprows = 1, names=['pos', 'reac'], engine='python')\n",
    "shape_1ai = shape_1ai.replace(to_replace = -999, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot COVERAGE QC\n",
    "fig1, axs = plt.subplots(1,1, figsize=(6,4))\n",
    "axs.plot(cov_con['pos'], cov_con['cov']/len(sum_con_fl), label='unmodified')\n",
    "axs.plot(cov_5['pos'], cov_5['cov']/len(sum_5_fl), label='5mM 1AI')\n",
    "axs.plot(cov_20['pos'], cov_20['cov']/len(sum_20_fl), label='20mM 1AI')\n",
    "axs.plot(cov_50['pos'], cov_50['cov']/len(sum_50_fl), label='50mM 1AI')\n",
    "axs.plot(cov_75['pos'], cov_75['cov']/len(sum_75_fl), label='75mM 1AI')\n",
    "axs.plot(cov_100['pos'], cov_100['cov']/len(sum_100_fl), label='100mM 1AI')\n",
    "axs.plot(cov_150['pos'], cov_150['cov']/len(sum_150_fl), label='150mM 1AI')\n",
    "axs.plot(cov_200['pos'], cov_200['cov']/len(sum_200_fl), label='200mM 1AI')\n",
    "\n",
    "axs.set_ylabel('Normalized Coverage')\n",
    "axs.set_xlabel('Position [nt]')\n",
    "_=axs.legend(loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUALITY SCORE AND READ LENGTH QC\n",
    "cmap = 'YlGn'\n",
    "\n",
    "## function to filter reads based on length\n",
    "def filter_reads(df_in, minlen, maxlen):\n",
    "    return df_in[(df_in['sequence_length_template'] >= minlen) & (df_in['sequence_length_template'] < maxlen)]\n",
    "\n",
    "min_len = 50  ## minimum read length\n",
    "max_len = 1200 ## maximum read length\n",
    "\n",
    "lens_con_fl  = filter_reads(sum_con_fl, min_len, max_len)\n",
    "lens_mod5_fl  = filter_reads(sum_5_fl, min_len, max_len)\n",
    "lens_mod20_fl  = filter_reads(sum_20_fl, min_len, max_len)\n",
    "lens_mod50_fl  = filter_reads(sum_50_fl, min_len, max_len)\n",
    "lens_mod75_fl  = filter_reads(sum_75_fl, min_len, max_len)\n",
    "lens_mod100_fl  = filter_reads(sum_100_fl, min_len, max_len)\n",
    "lens_mod150_fl  = filter_reads(sum_150_fl, min_len, max_len)\n",
    "lens_mod200_fl = filter_reads(sum_200_fl, min_len, max_len)\n",
    "\n",
    "X = [lens_con_fl, lens_mod5_fl, lens_mod20_fl, lens_mod50_fl, lens_mod75_fl, lens_mod100_fl, lens_mod150_fl, lens_mod200_fl ]\n",
    "\n",
    "fig2, axs = plt.subplots(1,8, figsize=(20,2.5), sharey=True, sharex=True)\n",
    "i=0\n",
    "titles=['unmodified', '5mM', '20mM', '50mM', '75mM', '100mM', '150mM', '200mM']\n",
    "for ax in axs.flat:\n",
    "    im = ax.hexbin(X[i]['sequence_length_template'], X[i]['mean_qscore_template'], cmap=cmap, bins='log')\n",
    "    ax.set_xlabel('Position [nt]')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_ylim(3,15)\n",
    "    i+=1\n",
    "fig2.subplots_adjust(right=0.82)\n",
    "cbar_ax = fig2.add_axes([0.85, 0.2, 0.01, 0.7])\n",
    "axs[0].set_ylabel('Quality Score')\n",
    "_=fig2.colorbar(im, cax=cbar_ax) \n",
    "#fig2.savefig('plots/qc_heatmap_1792_1ai_v1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of full length reads\n",
    "\n",
    "mn_len=800\n",
    "mx_len=1100\n",
    "\n",
    "fracfull_len_con = len(filter_reads(sum_con_fl, mn_len, mx_len)) / len(filter_reads(sum_con_fl, 100, 1200))\n",
    "fracfull_len_5   = len(filter_reads(sum_5_fl, mn_len, mx_len)) / len(filter_reads(sum_5_fl, 100, 1200))\n",
    "fracfull_len_20   = len(filter_reads(sum_20_fl, mn_len, mx_len)) / len(filter_reads(sum_20_fl, 100, 1200))\n",
    "fracfull_len_50  = len(filter_reads(sum_50_fl, mn_len, mx_len)) / len(filter_reads(sum_50_fl, 100, 1200))\n",
    "fracfull_len_75  = len(filter_reads(sum_75_fl, mn_len, mx_len)) / len(filter_reads(sum_75_fl, 100, 1200))\n",
    "fracfull_len_100 = len(filter_reads(sum_100_fl, mn_len, mx_len)) / len(filter_reads(sum_100_fl, 100, 1200))\n",
    "fracfull_len_150 = len(filter_reads(sum_150_fl, mn_len, mx_len)) / len(filter_reads(sum_150_fl, 100, 1200))\n",
    "fracfull_len_200 = len(filter_reads(sum_200_fl, mn_len, mx_len)) / len(filter_reads(sum_200_fl, 100, 1200)) \n",
    "\n",
    "fracfull = [fracfull_len_con, fracfull_len_5, fracfull_len_20, \\\n",
    "            fracfull_len_50,fracfull_len_75, fracfull_len_100, \\\n",
    "            fracfull_len_150, fracfull_len_200]\n",
    "\n",
    "\n",
    "tombo_resq_unalign = [23.9, 16.4, 16.9, 29.0, 28.4, 33.4, 35.3, 84.6]  # Alignment not produced (%)\n",
    "hundreds   = [100] *len(tombo_resq_unalign)\n",
    "tombo_resq_align = np.subtract(hundreds,tombo_resq_unalign)\n",
    "\n",
    "tombo_resq_presm = [7.3, 4.8, 4.0, 8.2, 4.8, 4.2, 6.9, 4.4]  # Poor raw to expected signal matching (revert with `tombo filter clear_filters`) (%)\n",
    "tombo_resq_ebb   = [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0]  # Read event to sequence alignment extends beyond bandwidth  (%)\n",
    "\n",
    "\n",
    "median_qscore  = [lens_con_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod5_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod20_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod50_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod75_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod100_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod150_fl['mean_qscore_template'].median(),\\\n",
    "                 lens_mod200_fl['mean_qscore_template'].median()]\n",
    "\n",
    "mean_qscore  = [lens_con_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod5_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod20_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod50_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod75_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod100_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod150_fl['mean_qscore_template'].mean(),\\\n",
    "                 lens_mod200_fl['mean_qscore_template'].mean()]\n",
    "\n",
    "concs    = [0, 5, 20, 50, 75, 100, 150, 200]\n",
    "\n",
    "## plot the normalized coverage, frac full length reads, median Qscore, Alignment rates\n",
    "\n",
    "fig3, axs = plt.subplots(1,4, figsize=(18,4))\n",
    "axs[0].plot(cov_con['pos'], cov_con['cov']/len(sum_con_fl), label='unmodified')\n",
    "axs[0].plot(cov_5['pos'], cov_5['cov']/len(sum_5_fl), label='5mM')\n",
    "axs[0].plot(cov_20['pos'], cov_20['cov']/len(sum_20_fl), label='20mM')\n",
    "axs[0].plot(cov_50['pos'], cov_50['cov']/len(sum_50_fl), label='50mM')\n",
    "axs[0].plot(cov_75['pos'], cov_75['cov']/len(sum_75_fl), label='75mM')\n",
    "axs[0].plot(cov_100['pos'], cov_100['cov']/len(sum_100_fl), label='100mM')\n",
    "axs[0].plot(cov_150['pos'], cov_150['cov']/len(sum_150_fl), label='150mM')\n",
    "axs[0].plot(cov_200['pos'], cov_200['cov']/len(sum_200_fl), label='200mM')\n",
    "\n",
    "axs[0].set_ylabel('Normalized Coverage')\n",
    "axs[0].set_xlabel('Position [nt]')\n",
    "_=axs[0].legend(loc='upper left', fontsize=12)\n",
    "\n",
    "axs[1].plot(concs, fracfull, 'ro')\n",
    "axs[1].set_ylabel('Fraction of full length reads')\n",
    "axs[1].set_ylim(0, 0.5)\n",
    "_=axs[1].set_xlabel('AcIm concentration [mM]')\n",
    "\n",
    "axs[2].plot(concs, median_qscore, label='Median Qscore')\n",
    "axs[2].set_ylabel('Median Qscore')\n",
    "axs[2].set_xlabel('AcIm concentration [mM]')\n",
    "\n",
    "\n",
    "axs[3].plot(concs, tombo_resq_align)\n",
    "axs[3].set_ylabel('Aligned read (%) - Tombo')\n",
    "_=axs[3].set_xlabel('AcIm concentration [mM]')\n",
    "fig3.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read numbers table \n",
    "\n",
    "concs    = [0, 5, 20, 50, 75, 100, 150, 200]\n",
    "all_reads      =  [len(sum_con_fl), len(sum_5_fl), len(sum_20_fl), len(sum_50_fl), len(sum_75_fl), len(sum_100_fl), len(sum_150_fl),len(sum_200_fl)]\n",
    "fulllen_reads  =  [len(filter_reads(sum_con_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_5_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_20_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_50_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_75_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_100_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_150_fl, mn_len, mx_len)),\n",
    "                  len(filter_reads(sum_200_fl, mn_len, mx_len))]\n",
    "\n",
    "flongle_df = pd.DataFrame({'conc':concs, 'total':all_reads, 'full':fulllen_reads, 'qscore':median_qscore, 'tombo_align':tombo_resq_align })\n",
    "flongle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPARE KS (CURR) STAT\n",
    "# need to trim the dataframes to similar size for correlation calculation\n",
    "\n",
    "shape_trim_kscurr_5   = shape_1ai[7:944]\n",
    "shape_trim_kscurr_20  = shape_1ai[7:944]\n",
    "shape_trim_kscurr_50  = shape_1ai[7:944]\n",
    "shape_trim_kscurr_75  = shape_1ai[7:944]\n",
    "shape_trim_kscurr_100 = shape_1ai[7:944]\n",
    "shape_trim_kscurr_150 = shape_1ai[7:944]\n",
    "shape_trim_kscurr_200 = shape_1ai[9:944]\n",
    "\n",
    "spearman_kscurr_rho = [spearmanr(stat_5['stat'], shape_trim_kscurr_5['reac'])[0], \\\n",
    "                       spearmanr(stat_20['stat'], shape_trim_kscurr_20['reac'])[0], \\\n",
    "                       spearmanr(stat_50['stat'], shape_trim_kscurr_50['reac'])[0], \\\n",
    "                       spearmanr(stat_75['stat'], shape_trim_kscurr_75['reac'])[0], \\\n",
    "                       spearmanr(stat_100['stat'], shape_trim_kscurr_100['reac'])[0], \\\n",
    "                       spearmanr(stat_150['stat'], shape_trim_kscurr_150['reac'])[0], \\\n",
    "                       spearmanr(stat_200['stat'], shape_trim_kscurr_200['reac'])[0]]\n",
    "\n",
    "print(spearman_kscurr_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE KS (DWELL) STAT\n",
    "# need to trim the dataframes to similar size for correlation calculation\n",
    "\n",
    "shape_trim_ksdwell_5   = shape_1ai[15:935]\n",
    "shape_trim_ksdwell_20  = shape_1ai[15:935]\n",
    "shape_trim_ksdwell_50  = shape_1ai[15:935]\n",
    "shape_trim_ksdwell_75  = shape_1ai[15:935]\n",
    "shape_trim_ksdwell_100 = shape_1ai[15:935]\n",
    "shape_trim_ksdwell_150 = shape_1ai[15:935]\n",
    "shape_trim_ksdwell_200 = shape_1ai[15:935]\n",
    "\n",
    "# need to shift the stat values by Xr(10nt), dwell time registration distance\n",
    "nt_shift = 10\n",
    "\n",
    "stat_dw_5['pos'] = stat_dw_5['pos']-nt_shift\n",
    "stat_dw_20['pos'] = stat_dw_20['pos']-nt_shift\n",
    "stat_dw_50['pos'] = stat_dw_50['pos']-nt_shift\n",
    "stat_dw_75['pos'] = stat_dw_75['pos']-nt_shift\n",
    "stat_dw_100['pos'] = stat_dw_100['pos']-nt_shift\n",
    "stat_dw_150['pos'] = stat_dw_150['pos']-nt_shift\n",
    "stat_dw_200['pos'] = stat_dw_200['pos']-nt_shift\n",
    "\n",
    "spearman_ksdwell_rho = [spearmanr(stat_dw_5['stat'], shape_trim_ksdwell_5['reac'])[0], \\\n",
    "                        spearmanr(stat_dw_20['stat'], shape_trim_ksdwell_20['reac'])[0], \\\n",
    "                        spearmanr(stat_dw_50['stat'], shape_trim_ksdwell_50['reac'])[0], \\\n",
    "                        spearmanr(stat_dw_75['stat'], shape_trim_ksdwell_75['reac'])[0], \\\n",
    "                        spearmanr(stat_dw_100['stat'], shape_trim_ksdwell_100['reac'])[0], \\\n",
    "                        spearmanr(stat_dw_150['stat'], shape_trim_ksdwell_150['reac'])[0], \\\n",
    "                        spearmanr(stat_dw_200['stat'], shape_trim_ksdwell_200['reac'])[0]]\n",
    "\n",
    "print(spearman_ksdwell_rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load miR 17-92 data\n",
    "\n",
    "a25 = pd.read_csv('/gpfs/commons/groups/innovation/will/shapemap2/8-5-19_1792_nanocompare/shapemapper_out/a25_miR17-92_DNA_profile.txt', \\\n",
    "sep='\\t', usecols=['Nucleotide', 'Sequence', 'Modified_mutations', 'Modified_read_depth', \\\n",
    "'Modified_effective_depth', 'Modified_rate', 'Untreated_mutations', 'Untreated_read_depth', \\\n",
    "'Untreated_effective_depth', 'Untreated_rate', 'Reactivity_profile', 'Std_err', 'HQ_profile', 'HQ_stderr', \\\n",
    "'Norm_profile', 'Norm_stderr'], engine='python')\n",
    "\n",
    "n25 = pd.read_csv('/gpfs/commons/groups/innovation/will/shapemap2/8-5-19_1792_nanocompare/shapemapper_out/n25_miR17-92_DNA_profile.txt', \\\n",
    "sep='\\t', usecols=['Nucleotide', 'Sequence', 'Modified_mutations', 'Modified_read_depth', \\\n",
    "'Modified_effective_depth', 'Modified_rate', 'Untreated_mutations', 'Untreated_read_depth', \\\n",
    "'Untreated_effective_depth', 'Untreated_rate', 'Reactivity_profile', 'Std_err', 'HQ_profile', 'HQ_stderr', \\\n",
    "'Norm_profile', 'Norm_stderr'], engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [5, 20, 50, 75, 100, 200] # conc of 1ai [final] \n",
    "x1 = [5, 20, 50, 75, 100, 150, 200] # conc of 1ai [final] \n",
    "\n",
    "## plot of KS current and dwell as a function of AcIm concentration\n",
    "\n",
    "fig4, axs = plt.subplots(1,1, figsize=(6,6))\n",
    "axs.plot(x1, spearman_kscurr_rho, 'o-', label='KS current vs SHAPE')\n",
    "axs.plot(x1, spearman_ksdwell_rho, 'o-', label='KS dwell vs SHAPE')\n",
    "axs.set_ylabel('Spearman\\'s rho')\n",
    "axs.set_xlabel('1AI concentration [mM]')\n",
    "axs.set_ylim(-0.1,0.7)\n",
    "_=axs.legend(fontsize=11)\n",
    "#fig4.savefig('plots/corrs_1792_v2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots of tombo KS stat vs SHAPE-MaP reactivity profile\n",
    "\n",
    "fig107, axs = plt.subplots(7,1, figsize=(12,8), sharex=True)\n",
    "axs[0].plot(shape_1ai['pos'], shape_1ai['reac'])\n",
    "axs[1].plot(stat_5['pos'], stat_5['stat'], label='5mM')\n",
    "axs[2].plot(stat_20['pos'], stat_20['stat'], label='20mM')\n",
    "axs[3].plot(stat_50['pos'], stat_50['stat'], label='50mM')\n",
    "axs[4].plot(stat_75['pos'], stat_75['stat'], label='75mM')\n",
    "axs[5].plot(stat_100['pos'], stat_100['stat'], label='100mM')\n",
    "axs[6].plot(stat_150['pos'], stat_150['stat'], label='150mM')\n",
    "#axs.plot(stat_200['pos'], stat_200['stat'], label='200mM')\n",
    "\n",
    "for ax in axs.reshape(-1)[1:]:\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "\n",
    "axs[0].set_ylabel('SHAPE reactivity')\n",
    "axs[3].set_ylabel('KS effect size - Current')\n",
    "_=axs[6].set_xlabel('Nucleotide position')\n",
    "\n",
    "#fig107.savefig('plots/shape_prof_1792_ks_region_v3.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
